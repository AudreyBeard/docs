# メトリクス & パフォーマンス

## メトリクス

### システムメトリクスはどのくらいの頻度で収集されますか？

デフォルトでは、メトリクスは2秒ごとに収集され、30秒間で平均化されます。もし、より高解像度のメトリクスが必要な場合は、[contact@wandb.com](mailto:contact@wandb.com)までメールでお問い合わせください。

### コードやデータセットの例なしに、メトリクスのみをログに残すことはできますか？

**データセットの例**

デフォルトでは、データセットの例はログに残さないようになっています。ウェブインターフェースでの例の予測を確認するために、この機能を明示的にオンにすることができます。

**コードのログ**

コードのログをオフにするには2つの方法があります:

1. `WANDB_DISABLE_CODE` を `true` に設定して、すべてのコードトラッキングをオフにします。これにより、git SHA や diff パッチを拾わなくなります。
2. `WANDB_IGNORE_GLOBS` を `*.patch` に設定し、diff パッチの同期をサーバーにオフにします。これにより、ローカルでパッチを保持しつつ、[wandb restore](../track/save-restore.md) コマンドで適用することができます。

### 2つの異なる時間スケールでメトリクスをログに残すことはできますか？（例えば、バッチごとのトレーニング精度とエポックごとの検証精度をログに残したい）

はい、ログに残すメトリクスと一緒にインデックス（例： `batch` や `epoch`）をログに残すことでこれを実現できます。1つのステップでは `wandb.log({'train_accuracy': 0.9, 'batch': 200})` を呼び出し、別のステップでは `wandb.log({'val_accuracy': 0.8, 'epoch': 4})` を呼び出すことができます。その後、UIで各チャートのx軸に適切な値を設定できます。特定のインデックスのデフォルトのx軸を設定したい場合は、[Run.define\_metric()](https://docs.wandb.ai/ref/python/run#define\_metric) を使って行うことができます。上記の例では、次のようにします：

```python
wandb.init()

wandb.define_metric("batch")
wandb.define_metric("epoch")
```


```python
wandb.define_metric("train_accuracy", step_metric="batch")
wandb.define_metric("val_accuracy", step_metric="epoch")
```

### 時間とともに変化しないメトリック（最終評価精度など）はどのようにしてログに記録できますか？

`wandb.log({'final_accuracy': 0.9}` を使用すればこれが可能です。デフォルトでは、`wandb.log({'final_accuracy'})` は `wandb.settings['final_accuracy']` を更新します。これは、runs tableに表示される値です。

### runが完了した後に追加のメトリックをログに記録する方法は？

これを行うためのいくつかの方法があります。

複雑なワークフローの場合、複数のrunを使用して [`wandb.init`](../track/launch.md) 内のgroupパラメータを、1つの実験として実行されるすべてのプロセスで一意の値に設定することをお勧めします。[runs table](../app/pages/run-page.md)は、グループIDでテーブルを自動的にグループ化し、視覚化は期待通りの振る舞いをします。これにより、複数の実験やトレーニングrunを別々のプロセスとして実行し、結果を1か所にまとめてログに記録することができます。

シンプルなワークフローの場合は、`resume=True` および `id=UNIQUE_ID` を指定して `wandb.init` を呼び出し、その後同じ `id=UNIQUE_ID` で `wandb.init` を呼び出すことができます。次に、[`wandb.log`](../track/log/intro.md) または `wandb.summary` を使用して通常通りログに記録し、runsの値が更新されます。

いつでも、[API](https://docs.wandb.ai/library/public-api-guide#update-metrics-for-a-run-after-the-run-has-finished) を使って追加の評価メトリクスを追加することができます。

## パフォーマンス

### wandbはトレーニングを遅くするか？

wandbは、通常の使用法であれば、トレーニングのパフォーマンスにほとんど影響を与えません。wandbの通常の使用法とは、1秒に1回未満の頻度でログを記録し、各ステップで数メガバイト未満のデータをログに記録することを意味します。wandbは別のプロセスで実行され、関数呼び出しがブロックされないため、ネットワークが一時的にダウンしたり、ディスク上で断続的な読み書きの問題が発生したりしても、パフォーマンスに影響しません。ただし、短時間で大量のデータをログに記録することができますが、その場合はディスクI/Oの問題が発生することがあります。ご質問があれば、どうぞお気軽にお問い合わせください。

### プロジェクトごとに作成するrunの数は？

パフォーマンス上の理由から、プロジェクトごとに最大で約10kのrunを作成することをお勧めします。

### ハイパーパラメータ検索を整理するためのベストプラクティス
プロジェクトごとに1万回のrun（概算）が適切な限界であれば、`wandb.init()`でタグを設定し、各検索に対して一意のタグを持たせることをお勧めします。これにより、プロジェクトページのRunsテーブルでそのタグをクリックすることで、特定の検索に絞り込むことが簡単にできます。例えば、`wandb.init(tags='your_tag')`  このドキュメントは[こちら](../../ref/python/init.md)で見つけることができます。